{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a13ddc8",
   "metadata": {},
   "source": [
    "# HuggingFace Hub Experiment Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5f049f",
   "metadata": {},
   "source": [
    "If you want to view this example in Google Colab, see [here](https://colab.research.google.com/github/hegelai/prompttools/blob/main/examples/notebooks/HuggingFaceHub.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623f0cfe",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30f7dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet --force-reinstall prompttools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac35f8",
   "metadata": {},
   "source": [
    "## Setup imports and API keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edba05a",
   "metadata": {},
   "source": [
    "First, we'll need to set our API keys. If we are in DEBUG mode, we don't need to use a real HuggingFaceHub key, so for now we'll set them to empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcdc47b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DEBUG\"] = \"\"  # Set to \"1\" if you want to use debug mode.\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9f880cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "from prompttools.experiment import HuggingFaceHubExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622dea9a",
   "metadata": {},
   "source": [
    "## Run an experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3babfe5a",
   "metadata": {},
   "source": [
    "Next, we create our test inputs. We can iterate over models, inputs, and configurations like temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9114cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gpt2\"]\n",
    "prompts = [\n",
    "    \"Who was the first president?\",\n",
    "    \"Who was the first president of the USA?\",\n",
    "]\n",
    "task = [\"text-generation\"]\n",
    "temperatures = [0.0, 1.0]\n",
    "\n",
    "experiment = HuggingFaceHubExperiment(models, prompts, task, temperature=temperatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fa5450",
   "metadata": {},
   "source": [
    "We can then run the experiment to get results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83b33130",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266c13eb",
   "metadata": {},
   "source": [
    "## Evaluate the model response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebb8023",
   "metadata": {},
   "source": [
    "To evaluate the results, we'll use a pre-built eval function. We can use semantic distance to check if the model's response is similar to our expected output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ddbb951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompttools.utils import semantic_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e80dfeec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment.evaluate(\"similar_to_expected\", semantic_similarity, expected=[\"George Washington\"] * 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974d6065",
   "metadata": {},
   "source": [
    "Finally, we can visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d09c18e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response(s)</th>\n",
       "      <th>latency</th>\n",
       "      <th>similar_to_expected</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who was the first president?</td>\n",
       "      <td>Who was the first president?\\n\\nI think it was George Washington. I think it was John</td>\n",
       "      <td>0.662535</td>\n",
       "      <td>0.362770</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who was the first president?</td>\n",
       "      <td>Who was the first president?\\n\\nI think it was George Washington. I think it was John</td>\n",
       "      <td>0.405260</td>\n",
       "      <td>0.362770</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who was the first president of the USA?</td>\n",
       "      <td>Who was the first president of the USA?\\n\\nI think it was George Washington. I think</td>\n",
       "      <td>0.347595</td>\n",
       "      <td>0.348384</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who was the first president of the USA?</td>\n",
       "      <td>Who was the first president of the USA?\\n\\nI think it was George Washington. I think</td>\n",
       "      <td>0.366199</td>\n",
       "      <td>0.348384</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    prompt  \\\n",
       "0  Who was the first president?              \n",
       "1  Who was the first president?              \n",
       "2  Who was the first president of the USA?   \n",
       "3  Who was the first president of the USA?   \n",
       "\n",
       "                                                                             response(s)  \\\n",
       "0  Who was the first president?\\n\\nI think it was George Washington. I think it was John   \n",
       "1  Who was the first president?\\n\\nI think it was George Washington. I think it was John   \n",
       "2  Who was the first president of the USA?\\n\\nI think it was George Washington. I think    \n",
       "3  Who was the first president of the USA?\\n\\nI think it was George Washington. I think    \n",
       "\n",
       "    latency  similar_to_expected  temperature  \n",
       "0  0.662535  0.362770             0.0          \n",
       "1  0.405260  0.362770             1.0          \n",
       "2  0.347595  0.348384             0.0          \n",
       "3  0.366199  0.348384             1.0          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2d0a45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
