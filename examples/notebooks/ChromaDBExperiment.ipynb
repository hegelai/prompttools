{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a13ddc8",
   "metadata": {},
   "source": [
    "# ChromaDB Experiment Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623f0cfe",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "885dabeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet --force-reinstall prompttools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac35f8",
   "metadata": {},
   "source": [
    "## Setup imports and API keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842f1e47",
   "metadata": {},
   "source": [
    "We'll import the relevant `prompttools` modules to setup our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beaa70a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T07:13:56.823039Z",
     "start_time": "2023-07-20T07:13:55.927616Z"
    }
   },
   "outputs": [],
   "source": [
    "from prompttools.experiment import ChromaDBExperiment\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622dea9a",
   "metadata": {},
   "source": [
    "## Run an experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5650e31",
   "metadata": {},
   "source": [
    "One common use case is to compare two different embedding functions and how it may impact your document retrieval. We have can define what embedding functions we'd like to test here.\n",
    "\n",
    "Note: If you previously haven't downloaded these embedding models. This may kick off downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02140eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/miniconda3/envs/prompttools/lib/python3.11/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/Users/kevin/miniconda3/envs/prompttools/lib/python3.11/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  ) < LooseVersion(\"1.15\"):\n",
      "/Users/kevin/miniconda3/envs/prompttools/lib/python3.11/site-packages/tensorflow/python/debug/cli/debugger_cli_common.py:19: DeprecationWarning: module 'sre_constants' is deprecated\n",
      "  import sre_constants\n"
     ]
    }
   ],
   "source": [
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "\n",
    "emb_fns = [\n",
    "    embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"paraphrase-MiniLM-L3-v2\"),\n",
    "    embedding_functions.DefaultEmbeddingFunction(),\n",
    "]  # default is \"all-MiniLM-L6-v2\"\n",
    "emb_fns_names = [\"paraphrase-MiniLM-L3-v2\", \"default\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3babfe5a",
   "metadata": {},
   "source": [
    "Next, we create our test inputs. In this case, we would like to create a new ChromaDB collection.\n",
    "\n",
    "During the experiment, for each embedding function, a new ChromaDB collection will be temporarily created. The documents will be added into it. Then, we will query from it and examine the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9114cfbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T07:13:56.829960Z",
     "start_time": "2023-07-20T07:13:56.825481Z"
    }
   },
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "# You can also create and use `chromadb.PersistentClient` or `chromadb.HttpClient`\n",
    "TEST_COLLECTION_NAME = \"TEMPORARY_COLLECTION\"\n",
    "try:\n",
    "    chroma_client.delete_collection(TEST_COLLECTION_NAME)\n",
    "except Exception:\n",
    "    pass\n",
    "collection_name = TEST_COLLECTION_NAME\n",
    "\n",
    "use_existing_collection = False  # Specify that we want to create a collection during the experiment\n",
    "\n",
    "# Documents that will be added into the database\n",
    "add_to_collection_params = {\n",
    "    \"documents\": [\"This is a document\", \"This is another document\", \"This is the document.\"],\n",
    "    \"metadatas\": [{\"source\": \"my_source\"}, {\"source\": \"my_source\"}, {\"source\": \"my_source\"}],\n",
    "    \"ids\": [\"id1\", \"id2\", \"id3\"],\n",
    "}\n",
    "\n",
    "# Our test queries\n",
    "query_collection_params = {\"query_texts\": [\"This is a query document\", \"This is a another query document\"]}\n",
    "\n",
    "\n",
    "# Set up the experiment\n",
    "experiment = ChromaDBExperiment(\n",
    "    chroma_client,\n",
    "    collection_name,\n",
    "    use_existing_collection,\n",
    "    query_collection_params,\n",
    "    emb_fns,\n",
    "    emb_fns_names,\n",
    "    add_to_collection_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fa5450",
   "metadata": {},
   "source": [
    "We can then run the experiment to get results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83b33130",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T07:16:21.469371Z",
     "start_time": "2023-07-20T07:16:21.462342Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 10 is greater than number of elements in index 3, updating n_results = 3\n",
      "/Users/kevin/miniconda3/envs/prompttools/lib/python3.11/site-packages/chromadb/utils/read_write_lock.py:29: DeprecationWarning: notifyAll() is deprecated, use notify_all() instead\n",
      "  self._read_ready.notifyAll()\n",
      "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 10 is greater than number of elements in index 3, updating n_results = 3\n",
      "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 10 is greater than number of elements in index 3, updating n_results = 3\n",
      "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 10 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    }
   ],
   "source": [
    "experiment.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b013dca",
   "metadata": {},
   "source": [
    "We can visualize the result. In this case, the result of the second query \"This is a another query document\" is different.\n",
    "\n",
    "paraphrase-MiniLM-L3-v2: [id2, id3, id1]\n",
    "\n",
    "default (all-MiniLM-L6-v2) : [id2, id1, id3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01c7e682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_texts</th>\n",
       "      <th>embed_fn</th>\n",
       "      <th>top doc ids</th>\n",
       "      <th>distances</th>\n",
       "      <th>documents</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a query document</td>\n",
       "      <td>paraphrase-MiniLM-L3-v2</td>\n",
       "      <td>[id1, id3, id2]</td>\n",
       "      <td>[14.106966018676758, 14.294026374816895, 18.137874603271484]</td>\n",
       "      <td>[This is a document, This is the document., This is another document]</td>\n",
       "      <td>0.008508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a another query document</td>\n",
       "      <td>paraphrase-MiniLM-L3-v2</td>\n",
       "      <td>[id2, id3, id1]</td>\n",
       "      <td>[13.375584602355957, 16.815608978271484, 16.913410186767578]</td>\n",
       "      <td>[This is another document, This is the document., This is a document]</td>\n",
       "      <td>0.006097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a query document</td>\n",
       "      <td>default</td>\n",
       "      <td>[id1, id3, id2]</td>\n",
       "      <td>[0.7111212611198425, 0.8084275126457214, 1.010977029800415]</td>\n",
       "      <td>[This is a document, This is the document., This is another document]</td>\n",
       "      <td>0.020234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a another query document</td>\n",
       "      <td>default</td>\n",
       "      <td>[id2, id1, id3]</td>\n",
       "      <td>[0.7673601508140564, 0.8709302544593811, 0.9072309732437134]</td>\n",
       "      <td>[This is another document, This is a document, This is the document.]</td>\n",
       "      <td>0.020889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        query_texts                 embed_fn      top doc ids  \\\n",
       "0  This is a query document          paraphrase-MiniLM-L3-v2  [id1, id3, id2]   \n",
       "1  This is a another query document  paraphrase-MiniLM-L3-v2  [id2, id3, id1]   \n",
       "2  This is a query document          default                  [id1, id3, id2]   \n",
       "3  This is a another query document  default                  [id2, id1, id3]   \n",
       "\n",
       "                                                      distances  \\\n",
       "0  [14.106966018676758, 14.294026374816895, 18.137874603271484]   \n",
       "1  [13.375584602355957, 16.815608978271484, 16.913410186767578]   \n",
       "2  [0.7111212611198425, 0.8084275126457214, 1.010977029800415]    \n",
       "3  [0.7673601508140564, 0.8709302544593811, 0.9072309732437134]   \n",
       "\n",
       "                                                               documents  \\\n",
       "0  [This is a document, This is the document., This is another document]   \n",
       "1  [This is another document, This is the document., This is a document]   \n",
       "2  [This is a document, This is the document., This is another document]   \n",
       "3  [This is another document, This is a document, This is the document.]   \n",
       "\n",
       "    latency  \n",
       "0  0.008508  \n",
       "1  0.006097  \n",
       "2  0.020234  \n",
       "3  0.020889  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266c13eb",
   "metadata": {},
   "source": [
    "## Evaluate the model response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebb8023",
   "metadata": {},
   "source": [
    "To evaluate the results, we'll define an evaluation function. Sometimes, you know order of the most relevant document should be given a query, and you can compute the correlation between expected ranking and actual ranking.\n",
    "\n",
    "Note: there is a built-in version of this function that you can import (scroll further below to see an example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ddbb951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# For each query, you can define what the expected ranking is.\n",
    "EXPECTED_RANKING = {\n",
    "    \"This is a query document\": [\"id1\", \"id3\", \"id2\"],\n",
    "    \"This is a another query document\": [\"id2\", \"id3\", \"id1\"],\n",
    "}\n",
    "\n",
    "\n",
    "def measure_correlation(row: \"pandas.core.series.Series\", ranking_column_name: str = \"top doc ids\") -> float:\n",
    "    r\"\"\"\n",
    "    A simple test that compares the expected ranking for a given query with the actual ranking produced\n",
    "    by the embedding function being tested.\n",
    "    \"\"\"\n",
    "    input_query = row[\"query_texts\"]\n",
    "    correlation, _ = stats.spearmanr(row[ranking_column_name], EXPECTED_RANKING[input_query])\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974d6065",
   "metadata": {},
   "source": [
    "Finally, we can evaluate and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e80dfeec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment.evaluate(\"ranking_correlation\", measure_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d09c18e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_texts</th>\n",
       "      <th>embed_fn</th>\n",
       "      <th>top doc ids</th>\n",
       "      <th>distances</th>\n",
       "      <th>documents</th>\n",
       "      <th>latency</th>\n",
       "      <th>ranking_correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a query document</td>\n",
       "      <td>paraphrase-MiniLM-L3-v2</td>\n",
       "      <td>[id1, id3, id2]</td>\n",
       "      <td>[14.106966018676758, 14.294026374816895, 18.137874603271484]</td>\n",
       "      <td>[This is a document, This is the document., This is another document]</td>\n",
       "      <td>0.008508</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a another query document</td>\n",
       "      <td>paraphrase-MiniLM-L3-v2</td>\n",
       "      <td>[id2, id3, id1]</td>\n",
       "      <td>[13.375584602355957, 16.815608978271484, 16.913410186767578]</td>\n",
       "      <td>[This is another document, This is the document., This is a document]</td>\n",
       "      <td>0.006097</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a query document</td>\n",
       "      <td>default</td>\n",
       "      <td>[id1, id3, id2]</td>\n",
       "      <td>[0.7111212611198425, 0.8084275126457214, 1.010977029800415]</td>\n",
       "      <td>[This is a document, This is the document., This is another document]</td>\n",
       "      <td>0.020234</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a another query document</td>\n",
       "      <td>default</td>\n",
       "      <td>[id2, id1, id3]</td>\n",
       "      <td>[0.7673601508140564, 0.8709302544593811, 0.9072309732437134]</td>\n",
       "      <td>[This is another document, This is a document, This is the document.]</td>\n",
       "      <td>0.020889</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        query_texts                 embed_fn      top doc ids  \\\n",
       "0  This is a query document          paraphrase-MiniLM-L3-v2  [id1, id3, id2]   \n",
       "1  This is a another query document  paraphrase-MiniLM-L3-v2  [id2, id3, id1]   \n",
       "2  This is a query document          default                  [id1, id3, id2]   \n",
       "3  This is a another query document  default                  [id2, id1, id3]   \n",
       "\n",
       "                                                      distances  \\\n",
       "0  [14.106966018676758, 14.294026374816895, 18.137874603271484]   \n",
       "1  [13.375584602355957, 16.815608978271484, 16.913410186767578]   \n",
       "2  [0.7111212611198425, 0.8084275126457214, 1.010977029800415]    \n",
       "3  [0.7673601508140564, 0.8709302544593811, 0.9072309732437134]   \n",
       "\n",
       "                                                               documents  \\\n",
       "0  [This is a document, This is the document., This is another document]   \n",
       "1  [This is another document, This is the document., This is a document]   \n",
       "2  [This is a document, This is the document., This is another document]   \n",
       "3  [This is another document, This is a document, This is the document.]   \n",
       "\n",
       "    latency  ranking_correlation  \n",
       "0  0.008508  1.0                  \n",
       "1  0.006097  1.0                  \n",
       "2  0.020234  1.0                  \n",
       "3  0.020889 -1.0                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efc1459",
   "metadata": {},
   "source": [
    "You can also import the built-in version of the rank correlation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdeb0aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 10 is greater than number of elements in index 3, updating n_results = 3\n",
      "/Users/kevin/miniconda3/envs/prompttools/lib/python3.11/site-packages/chromadb/utils/read_write_lock.py:29: DeprecationWarning: notifyAll() is deprecated, use notify_all() instead\n",
      "  self._read_ready.notifyAll()\n",
      "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 10 is greater than number of elements in index 3, updating n_results = 3\n",
      "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 10 is greater than number of elements in index 3, updating n_results = 3\n",
      "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 10 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_texts</th>\n",
       "      <th>embed_fn</th>\n",
       "      <th>top doc ids</th>\n",
       "      <th>distances</th>\n",
       "      <th>documents</th>\n",
       "      <th>latency</th>\n",
       "      <th>ranking_correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a query document</td>\n",
       "      <td>paraphrase-MiniLM-L3-v2</td>\n",
       "      <td>[id1, id3, id2]</td>\n",
       "      <td>[14.106966018676758, 14.294026374816895, 18.137874603271484]</td>\n",
       "      <td>[This is a document, This is the document., This is another document]</td>\n",
       "      <td>0.005949</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a another query document</td>\n",
       "      <td>paraphrase-MiniLM-L3-v2</td>\n",
       "      <td>[id2, id3, id1]</td>\n",
       "      <td>[13.375584602355957, 16.815608978271484, 16.913410186767578]</td>\n",
       "      <td>[This is another document, This is the document., This is a document]</td>\n",
       "      <td>0.006486</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a query document</td>\n",
       "      <td>default</td>\n",
       "      <td>[id1, id3, id2]</td>\n",
       "      <td>[0.7111212611198425, 0.8084275126457214, 1.010977029800415]</td>\n",
       "      <td>[This is a document, This is the document., This is another document]</td>\n",
       "      <td>0.020484</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a another query document</td>\n",
       "      <td>default</td>\n",
       "      <td>[id2, id1, id3]</td>\n",
       "      <td>[0.7673601508140564, 0.8709302544593811, 0.9072309732437134]</td>\n",
       "      <td>[This is another document, This is a document, This is the document.]</td>\n",
       "      <td>0.021018</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        query_texts                 embed_fn      top doc ids  \\\n",
       "0  This is a query document          paraphrase-MiniLM-L3-v2  [id1, id3, id2]   \n",
       "1  This is a another query document  paraphrase-MiniLM-L3-v2  [id2, id3, id1]   \n",
       "2  This is a query document          default                  [id1, id3, id2]   \n",
       "3  This is a another query document  default                  [id2, id1, id3]   \n",
       "\n",
       "                                                      distances  \\\n",
       "0  [14.106966018676758, 14.294026374816895, 18.137874603271484]   \n",
       "1  [13.375584602355957, 16.815608978271484, 16.913410186767578]   \n",
       "2  [0.7111212611198425, 0.8084275126457214, 1.010977029800415]    \n",
       "3  [0.7673601508140564, 0.8709302544593811, 0.9072309732437134]   \n",
       "\n",
       "                                                               documents  \\\n",
       "0  [This is a document, This is the document., This is another document]   \n",
       "1  [This is another document, This is the document., This is a document]   \n",
       "2  [This is a document, This is the document., This is another document]   \n",
       "3  [This is another document, This is a document, This is the document.]   \n",
       "\n",
       "    latency  ranking_correlation  \n",
       "0  0.005949  1.0                  \n",
       "1  0.006486  1.0                  \n",
       "2  0.020484  1.0                  \n",
       "3  0.021018 -1.0                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from prompttools.utils import ranking_correlation\n",
    "\n",
    "EXPECTED_RANKING_LIST = [\n",
    "    [\"id1\", \"id3\", \"id2\"],\n",
    "    [\"id2\", \"id3\", \"id1\"],\n",
    "    [\"id1\", \"id3\", \"id2\"],\n",
    "    [\"id2\", \"id3\", \"id1\"],\n",
    "]\n",
    "\n",
    "experiment.run()\n",
    "experiment.evaluate(\"ranking_correlation\", ranking_correlation, expected_ranking=EXPECTED_RANKING_LIST)\n",
    "experiment.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf4a45b",
   "metadata": {},
   "source": [
    "You can also use auto evaluation. We will add an example of this in the near future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
