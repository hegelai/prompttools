{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c02b0509",
   "metadata": {},
   "source": [
    "# Semantic Similarity Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7b247c",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5e5b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet --force-reinstall prompttools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac35f8",
   "metadata": {},
   "source": [
    "## Setup imports and API keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edba05a",
   "metadata": {},
   "source": [
    "First, we'll need to set our API keys. If we are in DEBUG mode, we don't need to use a real OpenAI key, so for now we'll set them to empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed4e635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DEBUG\"] = \"\"  # Set to \"1\" if you want to use debug mode.\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3934db",
   "metadata": {},
   "source": [
    "Then we'll import the relevant `prompttools` modules to setup our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0841dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "from prompttools.harness import PromptTemplateExperimentationHarness\n",
    "from prompttools.experiment import OpenAICompletionExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b106a04",
   "metadata": {},
   "source": [
    "## Run experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43545ff",
   "metadata": {},
   "source": [
    "Next, we create our test inputs. For this example, we'll use a prompt template, which uses [jinja](https://jinja.palletsprojects.com/en/3.1.x/) for templating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbab6b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_templates = [\"Answer the following question: {{input}}\", \"Respond the following query: {{input}}\"]\n",
    "user_inputs = [{\"input\": \"Who was the first president?\"}, {\"input\": \"Who was the first president of the USA?\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d152fdf",
   "metadata": {},
   "source": [
    "Now we can define an experimentation harness for our inputs and model. We could also pass model arguments if, for example, we wanted to change the model temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b3086e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "harness = PromptTemplateExperimentationHarness(\n",
    "    OpenAICompletionExperiment, \"text-davinci-003\", prompt_templates, user_inputs, model_arguments={\"temperature\": 1.0}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f5463a",
   "metadata": {},
   "source": [
    "We can then run the experiment to get results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84304957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Answer the following question: Who was the first president?</td>\n",
       "      <td>\\n\\nThe first president of the United States was George Washington.</td>\n",
       "      <td>1.109592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Answer the following question: Who was the first president of the USA?</td>\n",
       "      <td>\\n\\nThe first President of the United States was George Washington, who was inaug</td>\n",
       "      <td>0.802870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Respond the following query: Who was the first president?</td>\n",
       "      <td>\\n\\nThe first president of the United States was George Washington.</td>\n",
       "      <td>0.799840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Respond the following query: Who was the first president of the USA?</td>\n",
       "      <td>\\n\\nThe first president of the United States was George Washington.</td>\n",
       "      <td>1.047151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   prompt  \\\n",
       "0  Answer the following question: Who was the first president?              \n",
       "1  Answer the following question: Who was the first president of the USA?   \n",
       "2  Respond the following query: Who was the first president?                \n",
       "3  Respond the following query: Who was the first president of the USA?     \n",
       "\n",
       "                                                                            response  \\\n",
       "0  \\n\\nThe first president of the United States was George Washington.                 \n",
       "1  \\n\\nThe first President of the United States was George Washington, who was inaug   \n",
       "2  \\n\\nThe first president of the United States was George Washington.                 \n",
       "3  \\n\\nThe first president of the United States was George Washington.                 \n",
       "\n",
       "    latency  \n",
       "0  1.109592  \n",
       "1  0.802870  \n",
       "2  0.799840  \n",
       "3  1.047151  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "harness.run()\n",
    "harness.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266c13eb",
   "metadata": {},
   "source": [
    "## Evaluate the model response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebb8023",
   "metadata": {},
   "source": [
    "To evaluate the results, we'll use a pre-built eval function. We can use semantic distance to check if the model's response is similar to our expected output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ddbb951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompttools.utils import semantic_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e80dfeec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/miniconda3/envs/prompttools/lib/python3.11/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/Users/kevin/miniconda3/envs/prompttools/lib/python3.11/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  ) < LooseVersion(\"1.15\"):\n",
      "/Users/kevin/miniconda3/envs/prompttools/lib/python3.11/site-packages/tensorflow/python/debug/cli/debugger_cli_common.py:19: DeprecationWarning: module 'sre_constants' is deprecated\n",
      "  import sre_constants\n"
     ]
    }
   ],
   "source": [
    "harness.evaluate(\"similar_to_expected\", semantic_similarity, expected=[\"George Washington\"] * 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974d6065",
   "metadata": {},
   "source": [
    "Finally, we can visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "233f25a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>latency</th>\n",
       "      <th>similar_to_expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Answer the following question: Who was the first president?</td>\n",
       "      <td>\\n\\nThe first president of the United States was George Washington.</td>\n",
       "      <td>1.109592</td>\n",
       "      <td>0.724732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Answer the following question: Who was the first president of the USA?</td>\n",
       "      <td>\\n\\nThe first President of the United States was George Washington, who was inaug</td>\n",
       "      <td>0.802870</td>\n",
       "      <td>0.663015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Respond the following query: Who was the first president?</td>\n",
       "      <td>\\n\\nThe first president of the United States was George Washington.</td>\n",
       "      <td>0.799840</td>\n",
       "      <td>0.724732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Respond the following query: Who was the first president of the USA?</td>\n",
       "      <td>\\n\\nThe first president of the United States was George Washington.</td>\n",
       "      <td>1.047151</td>\n",
       "      <td>0.724732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   prompt  \\\n",
       "0  Answer the following question: Who was the first president?              \n",
       "1  Answer the following question: Who was the first president of the USA?   \n",
       "2  Respond the following query: Who was the first president?                \n",
       "3  Respond the following query: Who was the first president of the USA?     \n",
       "\n",
       "                                                                            response  \\\n",
       "0  \\n\\nThe first president of the United States was George Washington.                 \n",
       "1  \\n\\nThe first President of the United States was George Washington, who was inaug   \n",
       "2  \\n\\nThe first president of the United States was George Washington.                 \n",
       "3  \\n\\nThe first president of the United States was George Washington.                 \n",
       "\n",
       "    latency  similar_to_expected  \n",
       "0  1.109592  0.724732             \n",
       "1  0.802870  0.663015             \n",
       "2  0.799840  0.724732             \n",
       "3  1.047151  0.724732             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "harness.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6173e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8c36bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
