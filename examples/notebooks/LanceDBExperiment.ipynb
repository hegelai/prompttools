{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a13ddc8",
   "metadata": {},
   "source": [
    "# LanceDB Experiment Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623f0cfe",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885dabeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet --force-reinstall prompttools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac35f8",
   "metadata": {},
   "source": [
    "## No setup required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beaa70a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T07:13:56.823039Z",
     "start_time": "2023-07-20T07:13:55.927616Z"
    }
   },
   "outputs": [],
   "source": [
    "from prompttools.experiment import LanceDBExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622dea9a",
   "metadata": {},
   "source": [
    "## Run an experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5650e31",
   "metadata": {},
   "source": [
    "One common use case is to compare two different embedding functions and how it may impact your document retrieval. We have can define what embedding functions we'd like to test here.\n",
    "\n",
    "Note: If you previously haven't downloaded these embedding models. This may kick off downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "821bbb21-292c-44e5-bdf0-ab05350acb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevin/miniconda3/envs/prompttools/lib/python3.11/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/Users/kevin/miniconda3/envs/prompttools/lib/python3.11/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  ) < LooseVersion(\"1.15\"):\n",
      "/Users/kevin/miniconda3/envs/prompttools/lib/python3.11/site-packages/tensorflow/python/debug/cli/debugger_cli_common.py:19: DeprecationWarning: module 'sre_constants' is deprecated\n",
      "  import sre_constants\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "DEFAULT = SentenceTransformer(\"paraphrase-MiniLM-L3-v2\")\n",
    "MIMNILM_L6 = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def default_embed_func(batch):\n",
    "    return [DEFAULT.encode(sentence) for sentence in batch]\n",
    "\n",
    "def minilm_l6_embed_func(batch):\n",
    "    return [MIMNILM_L6.encode(sentence) for sentence in batch]\n",
    "\n",
    "emb_fns = {\"openai-ada-002\": default_embed_func, \"default\": minilm_l6_embed_func}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3babfe5a",
   "metadata": {},
   "source": [
    "Next, we create our test inputs. In this case, we would like to create a new ChromaDB collection.\n",
    "\n",
    "During the experiment, for each embedding function, a new ChromaDB collection will be temporarily created. The documents will be added into it. Then, we will query from it and examine the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9114cfbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T07:13:56.829960Z",
     "start_time": "2023-07-20T07:13:56.825481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "use_existing_table = False  # Specify that we want to create a collection during the experiment\n",
    "\n",
    "# Documents that will be added into the database. LanceDB also accepts other dataset formats like pydict, pyarrow, Pydantic etc.\n",
    "# Learn more here - https://lancedb.github.io/lancedb/guides/tables/\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    \"text\": [\"This is a document\", \"This is another document\", \"This is the document.\"],\n",
    "    \"metadatas\": [{\"source\": \"my_source\"}, {\"source\": \"my_source\"}, {\"source\": \"my_source\"}],\n",
    "    \"ids\": [\"id1\", \"id2\", \"id3\"],\n",
    "})\n",
    "\n",
    "query_args = {\"text\": [\"This is a query document\", \"This is a another query document\"], \"metric\": [\"cosine\", \"l2\"]}\n",
    "\n",
    "\n",
    "# Set up the experiment\n",
    "experiment = LanceDBExperiment(\n",
    "    data=data,\n",
    "    embedding_fns=emb_fns,\n",
    "    query_args=query_args,\n",
    ")\n",
    "\n",
    "# [Optional] Advanced query args \n",
    "# Our test queries, along with optional query args. LanceDB query accepts a few args to customize your search:\n",
    "# metrics: \"l2\", \"cosine\", or \"dot\" (cosine by default)\n",
    "# filter: SQL where clause to filter the vector search results before applying the limit. (None by default)\n",
    "# limit: number of results to return (3 by default)\n",
    "\"\"\"\n",
    "query_args_adv = {\n",
    "                \"text\": [\"This is a query document\", \"This is a another query document\"], \n",
    "                \"metric\": [\"cosine\", \"l2\", \"dot\"],\n",
    "                \"filter\": [\"text IS NOT NULL\" , \"text LIKE '%document.%'\"]\n",
    "                }\n",
    "experiment = LanceDBExperiment(\n",
    "    data=data,\n",
    "    embedding_fns=emb_fns,\n",
    "    query_args=query_args_adv,\n",
    " \n",
    ")\n",
    "\"\"\"\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fa5450",
   "metadata": {},
   "source": [
    "We can then run the experiment to get results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83b33130",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-20T07:16:21.469371Z",
     "start_time": "2023-07-20T07:16:21.462342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: rate limit only support up to 3.10, proceeding without rate limiter\n",
      "WARNING: rate limit only support up to 3.10, proceeding without rate limiter\n"
     ]
    }
   ],
   "source": [
    "experiment.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b013dca",
   "metadata": {},
   "source": [
    "We can visualize the result. In this case, the result of the second query \"This is a another query document\" is different.\n",
    "\n",
    "paraphrase-MiniLM-L3-v2: [id2, id3, id1]\n",
    "\n",
    "default (all-MiniLM-L6-v2) : [id2, id1, id3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01c7e682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>metric</th>\n",
       "      <th>emb_fn</th>\n",
       "      <th>top doc ids</th>\n",
       "      <th>distances</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a query document</td>\n",
       "      <td>cosine</td>\n",
       "      <td>openai-ada-002</td>\n",
       "      <td>[id2, id3, id1]</td>\n",
       "      <td>[0.7633732557296753, 0.773878812789917, 0.7882261872291565]</td>\n",
       "      <td>[This is another document, This is the document., This is a document]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a query document</td>\n",
       "      <td>l2</td>\n",
       "      <td>openai-ada-002</td>\n",
       "      <td>[id3, id1, id2]</td>\n",
       "      <td>[45.84406280517578, 49.12738037109375, 49.839256286621094]</td>\n",
       "      <td>[This is the document., This is a document, This is another document]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a another query document</td>\n",
       "      <td>cosine</td>\n",
       "      <td>openai-ada-002</td>\n",
       "      <td>[id2, id3, id1]</td>\n",
       "      <td>[0.7633732557296753, 0.773878812789917, 0.7882261872291565]</td>\n",
       "      <td>[This is another document, This is the document., This is a document]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a another query document</td>\n",
       "      <td>l2</td>\n",
       "      <td>openai-ada-002</td>\n",
       "      <td>[id3, id1, id2]</td>\n",
       "      <td>[45.84406280517578, 49.12738037109375, 49.839256286621094]</td>\n",
       "      <td>[This is the document., This is a document, This is another document]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is a query document</td>\n",
       "      <td>cosine</td>\n",
       "      <td>default</td>\n",
       "      <td>[id1, id3, id2]</td>\n",
       "      <td>[0.8099705576896667, 0.8289484977722168, 0.8308900594711304]</td>\n",
       "      <td>[This is a document, This is the document., This is another document]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This is a query document</td>\n",
       "      <td>l2</td>\n",
       "      <td>default</td>\n",
       "      <td>[id1, id3, id2]</td>\n",
       "      <td>[1.619940996170044, 1.6578971147537231, 1.6617801189422607]</td>\n",
       "      <td>[This is a document, This is the document., This is another document]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This is a another query document</td>\n",
       "      <td>cosine</td>\n",
       "      <td>default</td>\n",
       "      <td>[id1, id3, id2]</td>\n",
       "      <td>[0.8099705576896667, 0.8289484977722168, 0.8308900594711304]</td>\n",
       "      <td>[This is a document, This is the document., This is another document]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This is a another query document</td>\n",
       "      <td>l2</td>\n",
       "      <td>default</td>\n",
       "      <td>[id1, id3, id2]</td>\n",
       "      <td>[1.619940996170044, 1.6578971147537231, 1.6617801189422607]</td>\n",
       "      <td>[This is a document, This is the document., This is another document]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               text  metric          emb_fn      top doc ids  \\\n",
       "0  This is a query document          cosine  openai-ada-002  [id2, id3, id1]   \n",
       "1  This is a query document          l2      openai-ada-002  [id3, id1, id2]   \n",
       "2  This is a another query document  cosine  openai-ada-002  [id2, id3, id1]   \n",
       "3  This is a another query document  l2      openai-ada-002  [id3, id1, id2]   \n",
       "4  This is a query document          cosine  default         [id1, id3, id2]   \n",
       "5  This is a query document          l2      default         [id1, id3, id2]   \n",
       "6  This is a another query document  cosine  default         [id1, id3, id2]   \n",
       "7  This is a another query document  l2      default         [id1, id3, id2]   \n",
       "\n",
       "                                                      distances  \\\n",
       "0  [0.7633732557296753, 0.773878812789917, 0.7882261872291565]    \n",
       "1  [45.84406280517578, 49.12738037109375, 49.839256286621094]     \n",
       "2  [0.7633732557296753, 0.773878812789917, 0.7882261872291565]    \n",
       "3  [45.84406280517578, 49.12738037109375, 49.839256286621094]     \n",
       "4  [0.8099705576896667, 0.8289484977722168, 0.8308900594711304]   \n",
       "5  [1.619940996170044, 1.6578971147537231, 1.6617801189422607]    \n",
       "6  [0.8099705576896667, 0.8289484977722168, 0.8308900594711304]   \n",
       "7  [1.619940996170044, 1.6578971147537231, 1.6617801189422607]    \n",
       "\n",
       "                                                               documents  \n",
       "0  [This is another document, This is the document., This is a document]  \n",
       "1  [This is the document., This is a document, This is another document]  \n",
       "2  [This is another document, This is the document., This is a document]  \n",
       "3  [This is the document., This is a document, This is another document]  \n",
       "4  [This is a document, This is the document., This is another document]  \n",
       "5  [This is a document, This is the document., This is another document]  \n",
       "6  [This is a document, This is the document., This is another document]  \n",
       "7  [This is a document, This is the document., This is another document]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266c13eb",
   "metadata": {},
   "source": [
    "## Evaluate the model response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebb8023",
   "metadata": {},
   "source": [
    "To evaluate the results, we'll define an evaluation function. Sometimes, you know order of the most relevant document should be given a query, and you can compute the correlation between expected ranking and actual ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ddbb951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# For each query, you can define what the expected ranking is.\n",
    "EXPECTED_RANKING = {\n",
    "    \"This is a query document\": [\"id1\", \"id3\", \"id2\"],\n",
    "    \"This is a another query document\": [\"id2\", \"id3\", \"id1\"],\n",
    "}\n",
    "\n",
    "\n",
    "def measure_correlation(row: \"pandas.core.series.Series\", ranking_column_name: str = \"top doc ids\") -> float:\n",
    "    r\"\"\"\n",
    "    A simple test that compares the expected ranking for a given query with the actual ranking produced\n",
    "    by the embedding function being tested.\n",
    "    \"\"\"\n",
    "    input_query = row[\"text\"]\n",
    "    correlation, _ = stats.spearmanr(row[ranking_column_name], EXPECTED_RANKING[input_query])\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974d6065",
   "metadata": {},
   "source": [
    "Finally, we can evaluate and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e80dfeec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment.evaluate(\"ranking_correlation\", measure_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d09c18e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>metric</th>\n",
       "      <th>emb_fn</th>\n",
       "      <th>top doc ids</th>\n",
       "      <th>distances</th>\n",
       "      <th>documents</th>\n",
       "      <th>ranking_correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a query document</td>\n",
       "      <td>cosine</td>\n",
       "      <td>openai-ada-002</td>\n",
       "      <td>[id2, id3, id1]</td>\n",
       "      <td>[0.7633732557296753, 0.773878812789917, 0.7882261872291565]</td>\n",
       "      <td>[This is another document, This is the document., This is a document]</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a query document</td>\n",
       "      <td>l2</td>\n",
       "      <td>openai-ada-002</td>\n",
       "      <td>[id3, id1, id2]</td>\n",
       "      <td>[45.84406280517578, 49.12738037109375, 49.839256286621094]</td>\n",
       "      <td>[This is the document., This is a document, This is another document]</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a another query document</td>\n",
       "      <td>cosine</td>\n",
       "      <td>openai-ada-002</td>\n",
       "      <td>[id2, id3, id1]</td>\n",
       "      <td>[0.7633732557296753, 0.773878812789917, 0.7882261872291565]</td>\n",
       "      <td>[This is another document, This is the document., This is a document]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a another query document</td>\n",
       "      <td>l2</td>\n",
       "      <td>openai-ada-002</td>\n",
       "      <td>[id3, id1, id2]</td>\n",
       "      <td>[45.84406280517578, 49.12738037109375, 49.839256286621094]</td>\n",
       "      <td>[This is the document., This is a document, This is another document]</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is a query document</td>\n",
       "      <td>cosine</td>\n",
       "      <td>default</td>\n",
       "      <td>[id1, id3, id2]</td>\n",
       "      <td>[0.8099705576896667, 0.8289484977722168, 0.8308900594711304]</td>\n",
       "      <td>[This is a document, This is the document., This is another document]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This is a query document</td>\n",
       "      <td>l2</td>\n",
       "      <td>default</td>\n",
       "      <td>[id1, id3, id2]</td>\n",
       "      <td>[1.619940996170044, 1.6578971147537231, 1.6617801189422607]</td>\n",
       "      <td>[This is a document, This is the document., This is another document]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This is a another query document</td>\n",
       "      <td>cosine</td>\n",
       "      <td>default</td>\n",
       "      <td>[id1, id3, id2]</td>\n",
       "      <td>[0.8099705576896667, 0.8289484977722168, 0.8308900594711304]</td>\n",
       "      <td>[This is a document, This is the document., This is another document]</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This is a another query document</td>\n",
       "      <td>l2</td>\n",
       "      <td>default</td>\n",
       "      <td>[id1, id3, id2]</td>\n",
       "      <td>[1.619940996170044, 1.6578971147537231, 1.6617801189422607]</td>\n",
       "      <td>[This is a document, This is the document., This is another document]</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               text  metric          emb_fn      top doc ids  \\\n",
       "0  This is a query document          cosine  openai-ada-002  [id2, id3, id1]   \n",
       "1  This is a query document          l2      openai-ada-002  [id3, id1, id2]   \n",
       "2  This is a another query document  cosine  openai-ada-002  [id2, id3, id1]   \n",
       "3  This is a another query document  l2      openai-ada-002  [id3, id1, id2]   \n",
       "4  This is a query document          cosine  default         [id1, id3, id2]   \n",
       "5  This is a query document          l2      default         [id1, id3, id2]   \n",
       "6  This is a another query document  cosine  default         [id1, id3, id2]   \n",
       "7  This is a another query document  l2      default         [id1, id3, id2]   \n",
       "\n",
       "                                                      distances  \\\n",
       "0  [0.7633732557296753, 0.773878812789917, 0.7882261872291565]    \n",
       "1  [45.84406280517578, 49.12738037109375, 49.839256286621094]     \n",
       "2  [0.7633732557296753, 0.773878812789917, 0.7882261872291565]    \n",
       "3  [45.84406280517578, 49.12738037109375, 49.839256286621094]     \n",
       "4  [0.8099705576896667, 0.8289484977722168, 0.8308900594711304]   \n",
       "5  [1.619940996170044, 1.6578971147537231, 1.6617801189422607]    \n",
       "6  [0.8099705576896667, 0.8289484977722168, 0.8308900594711304]   \n",
       "7  [1.619940996170044, 1.6578971147537231, 1.6617801189422607]    \n",
       "\n",
       "                                                               documents  \\\n",
       "0  [This is another document, This is the document., This is a document]   \n",
       "1  [This is the document., This is a document, This is another document]   \n",
       "2  [This is another document, This is the document., This is a document]   \n",
       "3  [This is the document., This is a document, This is another document]   \n",
       "4  [This is a document, This is the document., This is another document]   \n",
       "5  [This is a document, This is the document., This is another document]   \n",
       "6  [This is a document, This is the document., This is another document]   \n",
       "7  [This is a document, This is the document., This is another document]   \n",
       "\n",
       "   ranking_correlation  \n",
       "0  0.5                  \n",
       "1 -1.0                  \n",
       "2  1.0                  \n",
       "3 -0.5                  \n",
       "4  1.0                  \n",
       "5  1.0                  \n",
       "6  0.5                  \n",
       "7  0.5                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf4a45b",
   "metadata": {},
   "source": [
    "You can also use auto evaluation. We will add an example of this in the near future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
